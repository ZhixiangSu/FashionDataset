{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main_TPU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"rujl71t5p_tS"},"source":["!rm *.png"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQk52ZxrK7OC"},"source":["!rm -rf FashionDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy2AcvEweGpw","executionInfo":{"status":"ok","timestamp":1634349518137,"user_tz":-480,"elapsed":28955,"user":{"displayName":"苏志翔","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06444298763113069178"}},"outputId":"f24a5ce4-516c-40fd-f3da-b8515a2eef0c"},"source":["!git clone https://github.com/szx159753/FashionDataset.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FashionDataset'...\n","remote: Enumerating objects: 14, done.\u001b[K\n","remote: Counting objects: 100% (14/14), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 14 (delta 2), reused 14 (delta 2), pack-reused 0\u001b[K\n","Unpacking objects: 100% (14/14), done.\n","Checking out files: 100% (6/6), done.\n"]}]},{"cell_type":"code","metadata":{"id":"_3Hqd7KtIx9O"},"source":["!mv FashionDataset/focal_loss.py /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0w-mUhxMwFD"},"source":["!tar xvf FashionDataset/data.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7wrQqdPXYJs-"},"source":["import os\n","print(os.environ[\"COLAB_TPU_ADDR\"])\n","\n","assert os.environ[\"COLAB_TPU_ADDR\"], \"Make sure to select TPU from Edit > Notebook settings > Hardware accelerator\"\n","\n","VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n","!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n","!python pytorch-xla-env-setup.py --version $VERSION"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwvA_lpa97oG"},"source":["from __future__ import print_function, division\n","import os\n","\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from collections import defaultdict\n","from torch.utils.data import DataLoader,Dataset\n","from torchvision.transforms import transforms\n","import subprocess\n","from focal_loss import FocalLoss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MLqzLVgJYMyV"},"source":["# imports pytorch\n","import torch\n","\n","# imports the torch_xla package\n","import torch_xla\n","import torch_xla.core.xla_model as xm\n","dev = xm.xla_device()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuE2D-SpXlAL"},"source":["data_dir='FashionDataset'\n","classes=[7,3,3,4,6,3]\n","# files={}\n","# labels={}\n","# for dir in ['train','val']:\n","#     files[dir]=open(os.path.join(data_dir,'split/'+dir+'.txt')).read().split('\\n')\n","#     labels[dir]=open(os.path.join(data_dir,'split/'+dir+'_attr.txt')).read().split('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MuJ2gLdXn_Z"},"source":["class MyDataset(Dataset):\n","    def __init__(self,dir,y_label=False):\n","        self.transform = transforms.Compose([\n","            transforms.Resize([224,224]),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        self.files=open(os.path.join(data_dir,'split/'+dir+'.txt')).read().split('\\n')[0:-1]\n","        self.len=len(self.files)\n","        self.y_label=y_label\n","\n","        bbox=open(os.path.join(data_dir,'split/'+dir+'_bbox.txt')).read().split('\\n')[0:-1]\n","        bbox=[bb.split(' ') for bb in bbox]\n","        self.bbox=bbox\n","        if self.y_label is True:\n","            labels=open(os.path.join(data_dir,'split/'+dir+'_attr.txt')).read().split('\\n')[0:-1]\n","            labels=[li.split(' ') for li in labels]\n","            self.labels=labels\n","    def __getitem__(self, idx):\n","        img_obj = Image.open(os.path.join(data_dir,self.files[idx]))\n","        bbox = np.array([int(l) for l in self.bbox[idx]],dtype=np.int)\n","        img_obj = img_obj.crop([bbox[0],bbox[1],bbox[2],bbox[3]])\n","        img_obj=self.transform(img_obj)\n","        if self.y_label is True:\n","            labels = np.array([int(l) for l in self.labels[idx]],dtype=np.float32)\n","            labels = torch.from_numpy(labels)\n","            return img_obj,labels\n","        else:\n","            return img_obj,self.files[idx]\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbOPb_sjXo1K"},"source":["image_datasets={x:MyDataset(x,y)\n","          for x,y in [['train',True],['val',True],['test',False]]}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=y, num_workers=2)\n","              for x,y in [['train',True],['val',True],['test',False]]}\n","\n","#device=torch.device(\"cpu\")\n","device=dev\n","#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AW_bBXiRX0_b"},"source":["def train_model(model, criterion, optimizer, scheduler, label_num,state,num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        phases=['train', 'val']\n","        if state=='iter':\n","          phases=['train']\n","        elif state=='final':\n","          phases=['train', 'val']\n","\n","        \n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels=labels[:,label_num]\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels.long())\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / len(image_datasets[phase])\n","            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                #torch.save(model.state_dict(), \"state_for_class_\" + str(label_num) + \".pth\")\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUCDdIwUX3YU"},"source":["def test_model(model):\n","    since = time.time()\n","    model.eval()  # Set model to evaluate mode\n","    predictions=torch.tensor([]).to(device)\n","        # Iterate over data.\n","    for inputs,file in dataloaders['test']:\n","        inputs = inputs.to(device)\n","        # forward\n","        # track history if only in train\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            predictions=torch.cat([predictions,preds],0)\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOp7J0UmX5c6"},"source":["def train(model_conv,class_num,state,epoch,lr):\n","\n","  num_ftrs = model_conv.fc.in_features\n","  model_conv.fc = nn.Linear(num_ftrs, classes[class_num])\n","  model_conv = model_conv.to(device)\n","\n","  criterion = FocalLoss()\n","\n","  # Observe that only parameters of final layer are being optimized as\n","  # opposed to before.\n","  #optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","  optimizer_conv = optim.SGD(model_conv.parameters(), lr=lr, momentum=0.7)\n","\n","  # Decay LR by a factor of 0.1 every 7 epochs\n","  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","  model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler,class_num,state, num_epochs=epoch)\n","  torch.save(model_conv.state_dict(),state+\"_state_for_class_\"+str(class_num)+\".pth\")\n","  return model_conv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybFMpj-NX7Zs"},"source":["def test(model,class_num):\n","  num_ftrs = model.fc.in_features\n","  model.fc = nn.Linear(num_ftrs, classes[class_num])\n","  model.load_state_dict(torch.load(\"final_state_for_class_\"+str(class_num)+\".pth\"))\n","  model = model.to(device)\n","\n","  # Observe that only parameters of final layer are being optimized as\n","  # opposed to before.\n","  # optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","  # optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n","\n","  # Decay LR by a factor of 0.1 every 7 epochs\n","  # exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","  labels = test_model(model)\n","  return labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJZM5xjRX8Ay"},"source":["iter=5\n","iter_epoch=1\n","model = torchvision.models.resnet50(pretrained=True)\n","for i in range(iter):\n","  for class_num in range(len(classes)):\n","    model = train(model,class_num,'iter',iter_epoch,lr=1)\n","\n","torch.save(model.state_dict(), \"state_after_iter\" + \".pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ye9KAbykPias","executionInfo":{"status":"ok","timestamp":1634355109212,"user_tz":-480,"elapsed":5166252,"user":{"displayName":"苏志翔","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06444298763113069178"}},"outputId":"9e578761-5d8e-49f3-c60f-5d4626f64d66"},"source":["epoch=30\n","model = torchvision.models.resnet50(pretrained=True)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, classes[2])\n","model.load_state_dict(torch.load(\"final_state_for_class_\"+str(2)+\".pth\"))\n","for class_num in range(3,len(classes)):\n","  # num_ftrs = model.fc.in_features\n","  # model.fc = nn.Linear(num_ftrs, classes[-1])\n","  # model.load_state_dict(torch.load(\"state_after_iter\" + \".pth\"))\n","  \n","  model = train(model,class_num,'final',epoch,lr=0.0001)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/29\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.8907 Acc: 0.6096\n","val Loss: 0.7321 Acc: 0.6970\n","\n","Epoch 1/29\n","----------\n","train Loss: 0.7766 Acc: 0.6666\n","val Loss: 0.6616 Acc: 0.7280\n","\n","Epoch 2/29\n","----------\n","train Loss: 0.6976 Acc: 0.7090\n","val Loss: 0.5567 Acc: 0.7770\n","\n","Epoch 3/29\n","----------\n","train Loss: 0.6419 Acc: 0.7528\n","val Loss: 0.5230 Acc: 0.7910\n","\n","Epoch 4/29\n","----------\n","train Loss: 0.6135 Acc: 0.7640\n","val Loss: 0.4984 Acc: 0.8170\n","\n","Epoch 5/29\n","----------\n","train Loss: 0.5926 Acc: 0.7782\n","val Loss: 0.5077 Acc: 0.8020\n","\n","Epoch 6/29\n","----------\n","train Loss: 0.5795 Acc: 0.7728\n","val Loss: 0.4777 Acc: 0.8130\n","\n","Epoch 7/29\n","----------\n","train Loss: 0.5277 Acc: 0.7966\n","val Loss: 0.4725 Acc: 0.8190\n","\n","Epoch 8/29\n","----------\n","train Loss: 0.5274 Acc: 0.8004\n","val Loss: 0.4819 Acc: 0.8140\n","\n","Epoch 9/29\n","----------\n","train Loss: 0.5367 Acc: 0.7970\n","val Loss: 0.4747 Acc: 0.8170\n","\n","Epoch 10/29\n","----------\n","train Loss: 0.5256 Acc: 0.8028\n","val Loss: 0.4682 Acc: 0.8280\n","\n","Epoch 11/29\n","----------\n","train Loss: 0.5180 Acc: 0.8056\n","val Loss: 0.4745 Acc: 0.8240\n","\n","Epoch 12/29\n","----------\n","train Loss: 0.5254 Acc: 0.7988\n","val Loss: 0.4795 Acc: 0.8170\n","\n","Epoch 13/29\n","----------\n","train Loss: 0.5208 Acc: 0.8068\n","val Loss: 0.4805 Acc: 0.8180\n","\n","Epoch 14/29\n","----------\n","train Loss: 0.5246 Acc: 0.7968\n","val Loss: 0.4654 Acc: 0.8200\n","\n","Epoch 15/29\n","----------\n","train Loss: 0.5158 Acc: 0.8094\n","val Loss: 0.4693 Acc: 0.8370\n","\n","Epoch 16/29\n","----------\n","train Loss: 0.5188 Acc: 0.8098\n","val Loss: 0.4679 Acc: 0.8220\n","\n","Epoch 17/29\n","----------\n","train Loss: 0.5299 Acc: 0.7986\n","val Loss: 0.4737 Acc: 0.8200\n","\n","Epoch 18/29\n","----------\n","train Loss: 0.5295 Acc: 0.7944\n","val Loss: 0.4623 Acc: 0.8170\n","\n","Epoch 19/29\n","----------\n","train Loss: 0.5254 Acc: 0.8038\n","val Loss: 0.4964 Acc: 0.8070\n","\n","Epoch 20/29\n","----------\n","train Loss: 0.5193 Acc: 0.8062\n","val Loss: 0.4718 Acc: 0.8170\n","\n","Epoch 21/29\n","----------\n","train Loss: 0.5216 Acc: 0.8038\n","val Loss: 0.4822 Acc: 0.8160\n","\n","Epoch 22/29\n","----------\n","train Loss: 0.5277 Acc: 0.8032\n","val Loss: 0.5005 Acc: 0.8080\n","\n","Epoch 23/29\n","----------\n","train Loss: 0.5260 Acc: 0.8044\n","val Loss: 0.4674 Acc: 0.8270\n","\n","Epoch 24/29\n","----------\n","train Loss: 0.5072 Acc: 0.8100\n","val Loss: 0.4702 Acc: 0.8160\n","\n","Epoch 25/29\n","----------\n","train Loss: 0.5259 Acc: 0.8038\n","val Loss: 0.4810 Acc: 0.8130\n","\n","Epoch 26/29\n","----------\n","train Loss: 0.5263 Acc: 0.8030\n","val Loss: 0.4675 Acc: 0.8230\n","\n","Epoch 27/29\n","----------\n","train Loss: 0.5265 Acc: 0.8020\n","val Loss: 0.4667 Acc: 0.8240\n","\n","Epoch 28/29\n","----------\n","train Loss: 0.5131 Acc: 0.8104\n","val Loss: 0.5320 Acc: 0.7960\n","\n","Epoch 29/29\n","----------\n","train Loss: 0.5054 Acc: 0.8136\n","val Loss: 0.4752 Acc: 0.8230\n","\n","Training complete in 28m 48s\n","Best val Acc: 0.837000\n","Epoch 0/29\n","----------\n","train Loss: 1.0119 Acc: 0.6760\n","val Loss: 0.9139 Acc: 0.6830\n","\n","Epoch 1/29\n","----------\n","train Loss: 0.9151 Acc: 0.6852\n","val Loss: 0.8428 Acc: 0.6970\n","\n","Epoch 2/29\n","----------\n","train Loss: 0.8569 Acc: 0.7026\n","val Loss: 0.7950 Acc: 0.7100\n","\n","Epoch 3/29\n","----------\n","train Loss: 0.8004 Acc: 0.7200\n","val Loss: 0.7471 Acc: 0.7150\n","\n","Epoch 4/29\n","----------\n","train Loss: 0.7728 Acc: 0.7214\n","val Loss: 0.7189 Acc: 0.7250\n","\n","Epoch 5/29\n","----------\n","train Loss: 0.7379 Acc: 0.7392\n","val Loss: 0.7081 Acc: 0.7370\n","\n","Epoch 6/29\n","----------\n","train Loss: 0.7190 Acc: 0.7466\n","val Loss: 0.6977 Acc: 0.7360\n","\n","Epoch 7/29\n","----------\n","train Loss: 0.6946 Acc: 0.7488\n","val Loss: 0.7024 Acc: 0.7280\n","\n","Epoch 8/29\n","----------\n","train Loss: 0.6799 Acc: 0.7548\n","val Loss: 0.6895 Acc: 0.7330\n","\n","Epoch 9/29\n","----------\n","train Loss: 0.6926 Acc: 0.7506\n","val Loss: 0.6926 Acc: 0.7360\n","\n","Epoch 10/29\n","----------\n","train Loss: 0.6739 Acc: 0.7644\n","val Loss: 0.6906 Acc: 0.7380\n","\n","Epoch 11/29\n","----------\n","train Loss: 0.6911 Acc: 0.7576\n","val Loss: 0.6933 Acc: 0.7340\n","\n","Epoch 12/29\n","----------\n","train Loss: 0.6809 Acc: 0.7526\n","val Loss: 0.6953 Acc: 0.7240\n","\n","Epoch 13/29\n","----------\n","train Loss: 0.6827 Acc: 0.7562\n","val Loss: 0.6984 Acc: 0.7320\n","\n","Epoch 14/29\n","----------\n","train Loss: 0.6806 Acc: 0.7536\n","val Loss: 0.6812 Acc: 0.7400\n","\n","Epoch 15/29\n","----------\n","train Loss: 0.6718 Acc: 0.7582\n","val Loss: 0.6851 Acc: 0.7410\n","\n","Epoch 16/29\n","----------\n","train Loss: 0.6774 Acc: 0.7560\n","val Loss: 0.6780 Acc: 0.7480\n","\n","Epoch 17/29\n","----------\n","train Loss: 0.6765 Acc: 0.7586\n","val Loss: 0.6899 Acc: 0.7380\n","\n","Epoch 18/29\n","----------\n","train Loss: 0.6741 Acc: 0.7588\n","val Loss: 0.6935 Acc: 0.7370\n","\n","Epoch 19/29\n","----------\n","train Loss: 0.6900 Acc: 0.7548\n","val Loss: 0.6895 Acc: 0.7280\n","\n","Epoch 20/29\n","----------\n","train Loss: 0.6749 Acc: 0.7604\n","val Loss: 0.6833 Acc: 0.7450\n","\n","Epoch 21/29\n","----------\n","train Loss: 0.6729 Acc: 0.7566\n","val Loss: 0.6764 Acc: 0.7430\n","\n","Epoch 22/29\n","----------\n","train Loss: 0.6660 Acc: 0.7666\n","val Loss: 0.6925 Acc: 0.7300\n","\n","Epoch 23/29\n","----------\n","train Loss: 0.6876 Acc: 0.7598\n","val Loss: 0.6951 Acc: 0.7300\n","\n","Epoch 24/29\n","----------\n","train Loss: 0.6773 Acc: 0.7578\n","val Loss: 0.6828 Acc: 0.7360\n","\n","Epoch 25/29\n","----------\n","train Loss: 0.6796 Acc: 0.7572\n","val Loss: 0.6803 Acc: 0.7420\n","\n","Epoch 26/29\n","----------\n","train Loss: 0.6628 Acc: 0.7662\n","val Loss: 0.6939 Acc: 0.7280\n","\n","Epoch 27/29\n","----------\n","train Loss: 0.6714 Acc: 0.7584\n","val Loss: 0.6859 Acc: 0.7350\n","\n","Epoch 28/29\n","----------\n","train Loss: 0.6784 Acc: 0.7588\n","val Loss: 0.6856 Acc: 0.7310\n","\n","Epoch 29/29\n","----------\n","train Loss: 0.6730 Acc: 0.7572\n","val Loss: 0.6856 Acc: 0.7390\n","\n","Training complete in 28m 45s\n","Best val Acc: 0.748000\n","Epoch 0/29\n","----------\n","train Loss: 0.6073 Acc: 0.7894\n","val Loss: 0.5532 Acc: 0.8100\n","\n","Epoch 1/29\n","----------\n","train Loss: 0.5482 Acc: 0.8008\n","val Loss: 0.4990 Acc: 0.8170\n","\n","Epoch 2/29\n","----------\n","train Loss: 0.5221 Acc: 0.8098\n","val Loss: 0.4825 Acc: 0.8260\n","\n","Epoch 3/29\n","----------\n","train Loss: 0.4970 Acc: 0.8232\n","val Loss: 0.4607 Acc: 0.8300\n","\n","Epoch 4/29\n","----------\n","train Loss: 0.4775 Acc: 0.8254\n","val Loss: 0.4354 Acc: 0.8390\n","\n","Epoch 5/29\n","----------\n","train Loss: 0.4564 Acc: 0.8350\n","val Loss: 0.4388 Acc: 0.8460\n","\n","Epoch 6/29\n","----------\n","train Loss: 0.4407 Acc: 0.8436\n","val Loss: 0.4227 Acc: 0.8480\n","\n","Epoch 7/29\n","----------\n","train Loss: 0.4218 Acc: 0.8464\n","val Loss: 0.4406 Acc: 0.8350\n","\n","Epoch 8/29\n","----------\n","train Loss: 0.4239 Acc: 0.8516\n","val Loss: 0.4315 Acc: 0.8420\n","\n","Epoch 9/29\n","----------\n","train Loss: 0.4208 Acc: 0.8494\n","val Loss: 0.4301 Acc: 0.8450\n","\n","Epoch 10/29\n","----------\n","train Loss: 0.4211 Acc: 0.8522\n","val Loss: 0.4242 Acc: 0.8490\n","\n","Epoch 11/29\n","----------\n","train Loss: 0.4129 Acc: 0.8482\n","val Loss: 0.4206 Acc: 0.8490\n","\n","Epoch 12/29\n","----------\n","train Loss: 0.4080 Acc: 0.8524\n","val Loss: 0.4218 Acc: 0.8470\n","\n","Epoch 13/29\n","----------\n","train Loss: 0.4089 Acc: 0.8528\n","val Loss: 0.4104 Acc: 0.8580\n","\n","Epoch 14/29\n","----------\n","train Loss: 0.4150 Acc: 0.8490\n","val Loss: 0.4314 Acc: 0.8430\n","\n","Epoch 15/29\n","----------\n","train Loss: 0.4131 Acc: 0.8494\n","val Loss: 0.4179 Acc: 0.8460\n","\n","Epoch 16/29\n","----------\n","train Loss: 0.4111 Acc: 0.8486\n","val Loss: 0.4124 Acc: 0.8470\n","\n","Epoch 17/29\n","----------\n","train Loss: 0.4153 Acc: 0.8470\n","val Loss: 0.4204 Acc: 0.8490\n","\n","Epoch 18/29\n","----------\n","train Loss: 0.4108 Acc: 0.8522\n","val Loss: 0.4204 Acc: 0.8510\n","\n","Epoch 19/29\n","----------\n","train Loss: 0.4099 Acc: 0.8528\n","val Loss: 0.4207 Acc: 0.8440\n","\n","Epoch 20/29\n","----------\n","train Loss: 0.4141 Acc: 0.8476\n","val Loss: 0.4199 Acc: 0.8460\n","\n","Epoch 21/29\n","----------\n","train Loss: 0.4117 Acc: 0.8520\n","val Loss: 0.4154 Acc: 0.8520\n","\n","Epoch 22/29\n","----------\n","train Loss: 0.4051 Acc: 0.8552\n","val Loss: 0.4089 Acc: 0.8570\n","\n","Epoch 23/29\n","----------\n","train Loss: 0.4063 Acc: 0.8530\n","val Loss: 0.4225 Acc: 0.8470\n","\n","Epoch 24/29\n","----------\n","train Loss: 0.4092 Acc: 0.8498\n","val Loss: 0.4283 Acc: 0.8490\n","\n","Epoch 25/29\n","----------\n","train Loss: 0.4165 Acc: 0.8480\n","val Loss: 0.4095 Acc: 0.8530\n","\n","Epoch 26/29\n","----------\n","train Loss: 0.4040 Acc: 0.8550\n","val Loss: 0.4243 Acc: 0.8470\n","\n","Epoch 27/29\n","----------\n","train Loss: 0.4034 Acc: 0.8510\n","val Loss: 0.4271 Acc: 0.8510\n","\n","Epoch 28/29\n","----------\n","train Loss: 0.4034 Acc: 0.8544\n","val Loss: 0.4122 Acc: 0.8540\n","\n","Epoch 29/29\n","----------\n","train Loss: 0.4049 Acc: 0.8500\n","val Loss: 0.4244 Acc: 0.8440\n","\n","Training complete in 28m 22s\n","Best val Acc: 0.858000\n"]}]},{"cell_type":"code","metadata":{"id":"PUuTtVg6X91r"},"source":["model = torchvision.models.resnet50(pretrained=True)\n","result=[]\n","for class_num in range(len(classes)):\n","  predictions=test(model,class_num)\n","  result.append(predictions.cpu().numpy())\n","result=np.matrix(result)\n","result=result.T\n","np.savetxt('prediction.txt', np.c_[result],\n"," fmt='%d',delimiter='\\t')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Xk26HUA9VkX","executionInfo":{"elapsed":1716,"status":"ok","timestamp":1634228428471,"user":{"displayName":"苏志翔","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06444298763113069178"},"user_tz":-480},"outputId":"f79d900b-061e-4d77-8a19-c658a5f10074"},"source":["!tar -cvf state.tar *.pth"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["final_state_for_class_0.pth\n","final_state_for_class_1.pth\n","final_state_for_class_2.pth\n","final_state_for_class_3.pth\n","final_state_for_class_4.pth\n","final_state_for_class_5.pth\n"]}]}]}
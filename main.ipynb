{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bbdc0400bb6945e5b406d44840739c29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_310e6be5d04c40ae8e3177d86e9ce34d","IPY_MODEL_13c21f1dc5904f3ab724ecced532f7af","IPY_MODEL_ac38ec81f6b54176b75dd8b328959f12"],"layout":"IPY_MODEL_bdaf859702d241899d5a82bb9a8f8a3d"}},"310e6be5d04c40ae8e3177d86e9ce34d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ed27a9366f2472998c31696427c8445","placeholder":"​","style":"IPY_MODEL_e53730ed4b9548adb8d085b61ea3f784","value":"100%"}},"13c21f1dc5904f3ab724ecced532f7af":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_403957d123274dea9e13196c6594b7c5","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_083927d3b05b43d2a147596a2045bfe0","value":102530333}},"ac38ec81f6b54176b75dd8b328959f12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c579a3a49c14b61963300f27628cd70","placeholder":"​","style":"IPY_MODEL_db65f0c16f0a425e9b50ef9aa025362b","value":" 97.8M/97.8M [00:01&lt;00:00, 117MB/s]"}},"bdaf859702d241899d5a82bb9a8f8a3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ed27a9366f2472998c31696427c8445":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e53730ed4b9548adb8d085b61ea3f784":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"403957d123274dea9e13196c6594b7c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"083927d3b05b43d2a147596a2045bfe0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3c579a3a49c14b61963300f27628cd70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db65f0c16f0a425e9b50ef9aa025362b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"rujl71t5p_tS"},"source":["!rm *.png"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQk52ZxrK7OC"},"source":["!rm -rf FashionDataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iy2AcvEweGpw","executionInfo":{"elapsed":14133,"status":"ok","timestamp":1634283809313,"user":{"displayName":"SU ZHIXIANG","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00414688596049701256"},"user_tz":-480},"outputId":"ed9c6b04-8fea-4690-b9fc-2a11644e8574"},"source":["!git clone https://github.com/szx159753/FashionDataset.git"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'FashionDataset'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 11 (delta 0), reused 6 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (11/11), done.\n"]}]},{"cell_type":"code","metadata":{"id":"_3Hqd7KtIx9O"},"source":["!mv FashionDataset/focal_loss.py /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0w-mUhxMwFD"},"source":["!tar xvf FashionDataset/data.tar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KwvA_lpa97oG"},"source":["from __future__ import print_function, division\n","import os\n","\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","from collections import defaultdict\n","from torch.utils.data import DataLoader,Dataset\n","from torchvision.transforms import transforms\n","import subprocess\n","from focal_loss import FocalLoss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YuE2D-SpXlAL"},"source":["data_dir='FashionDataset'\n","classes=[7,3,3,4,6,3]\n","# files={}\n","# labels={}\n","# for dir in ['train','val']:\n","#     files[dir]=open(os.path.join(data_dir,'split/'+dir+'.txt')).read().split('\\n')\n","#     labels[dir]=open(os.path.join(data_dir,'split/'+dir+'_attr.txt')).read().split('\\n')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5MuJ2gLdXn_Z"},"source":["class MyDataset(Dataset):\n","    def __init__(self,dir,y_label=False):\n","        self.transform = transforms.Compose([\n","            transforms.Resize([224,224]),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","        self.files=open(os.path.join(data_dir,'split/'+dir+'.txt')).read().split('\\n')[0:-1]\n","        self.len=len(self.files)\n","        self.y_label=y_label\n","\n","        bbox=open(os.path.join(data_dir,'split/'+dir+'_bbox.txt')).read().split('\\n')[0:-1]\n","        bbox=[bb.split(' ') for bb in bbox]\n","        self.bbox=bbox\n","        if self.y_label is True:\n","            labels=open(os.path.join(data_dir,'split/'+dir+'_attr.txt')).read().split('\\n')[0:-1]\n","            labels=[li.split(' ') for li in labels]\n","            self.labels=labels\n","    def __getitem__(self, idx):\n","        img_obj = Image.open(os.path.join(data_dir,self.files[idx]))\n","        bbox = np.array([int(l) for l in self.bbox[idx]],dtype=np.int)\n","        img_obj = img_obj.crop([bbox[0],bbox[1],bbox[2],bbox[3]])\n","        img_obj=self.transform(img_obj)\n","        if self.y_label is True:\n","            labels = np.array([int(l) for l in self.labels[idx]],dtype=np.float32)\n","            labels = torch.from_numpy(labels)\n","            return img_obj,labels\n","        else:\n","            return img_obj,self.files[idx]\n","    def __len__(self):\n","        return len(self.files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbOPb_sjXo1K"},"source":["image_datasets={x:MyDataset(x,y)\n","          for x,y in [['train',True],['val',True],['test',False]]}\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=y, num_workers=2)\n","              for x,y in [['train',True],['val',True],['test',False]]}\n","\n","#device=torch.device(\"cpu\")\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AW_bBXiRX0_b"},"source":["def train_model(model, criterion, optimizer, scheduler, label_num,state,num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        phases=['train', 'val']\n","        if state=='iter':\n","          phases=['train']\n","        elif state=='final':\n","          phases=['train', 'val']\n","\n","        \n","        for phase in phases:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels=labels[:,label_num]\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels.long())\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / len(image_datasets[phase])\n","            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","                #torch.save(model.state_dict(), \"state_for_class_\" + str(label_num) + \".pth\")\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUCDdIwUX3YU"},"source":["def test_model(model):\n","    since = time.time()\n","    model.eval()  # Set model to evaluate mode\n","    predictions=torch.tensor([]).to(device)\n","        # Iterate over data.\n","    for inputs,file in dataloaders['test']:\n","        inputs = inputs.to(device)\n","        # forward\n","        # track history if only in train\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            predictions=torch.cat([predictions,preds],0)\n","    return predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dOp7J0UmX5c6"},"source":["def train(model_conv,class_num,state,epoch,lr):\n","\n","  num_ftrs = model_conv.fc.in_features\n","  model_conv.fc = nn.Linear(num_ftrs, classes[class_num])\n","  model_conv = model_conv.to(device)\n","\n","  criterion = FocalLoss()\n","\n","  # Observe that only parameters of final layer are being optimized as\n","  # opposed to before.\n","  #optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","  optimizer_conv = optim.SGD(model_conv.parameters(), lr=lr, momentum=0.7)\n","\n","  # Decay LR by a factor of 0.1 every 7 epochs\n","  exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","  model_conv = train_model(model_conv, criterion, optimizer_conv, exp_lr_scheduler,class_num,state, num_epochs=epoch)\n","  torch.save(model_conv.state_dict(),state+\"_state_for_class_\"+str(class_num)+\".pth\")\n","  return model_conv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ybFMpj-NX7Zs"},"source":["def test(model,class_num):\n","  num_ftrs = model.fc.in_features\n","  model.fc = nn.Linear(num_ftrs, classes[class_num])\n","  model.load_state_dict(torch.load(\"final_state_for_class_\"+str(class_num)+\".pth\"))\n","  model = model.to(device)\n","\n","  # Observe that only parameters of final layer are being optimized as\n","  # opposed to before.\n","  # optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n","  # optimizer_conv = optim.SGD(model_conv.parameters(), lr=0.001, momentum=0.9)\n","\n","  # Decay LR by a factor of 0.1 every 7 epochs\n","  # exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n","  labels = test_model(model)\n","  return labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GJZM5xjRX8Ay"},"source":["iter=5\n","iter_epoch=1\n","model = torchvision.models.resnet50(pretrained=True)\n","for i in range(iter):\n","  for class_num in range(len(classes)):\n","    model = train(model,class_num,'iter',iter_epoch,lr=1)\n","\n","torch.save(model.state_dict(), \"state_after_iter\" + \".pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":429,"referenced_widgets":["bbdc0400bb6945e5b406d44840739c29","310e6be5d04c40ae8e3177d86e9ce34d","13c21f1dc5904f3ab724ecced532f7af","ac38ec81f6b54176b75dd8b328959f12","bdaf859702d241899d5a82bb9a8f8a3d","1ed27a9366f2472998c31696427c8445","e53730ed4b9548adb8d085b61ea3f784","403957d123274dea9e13196c6594b7c5","083927d3b05b43d2a147596a2045bfe0","3c579a3a49c14b61963300f27628cd70","db65f0c16f0a425e9b50ef9aa025362b"]},"id":"ye9KAbykPias","outputId":"080aba01-0b1d-48d2-8c56-82aa392241f6"},"source":["epoch=30\n","model = torchvision.models.resnet50(pretrained=True)\n","for class_num in range(len(classes)):\n","  # num_ftrs = model.fc.in_features\n","  # model.fc = nn.Linear(num_ftrs, classes[-1])\n","  # model.load_state_dict(torch.load(\"state_after_iter\" + \".pth\"))\n","  \n","  model = train(model,class_num,'final',epoch,lr=0.0001)\n"],"execution_count":null,"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbdc0400bb6945e5b406d44840739c29","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0/29\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]},{"name":"stdout","output_type":"stream","text":["train Loss: 1.3519 Acc: 0.5318\n","val Loss: 1.0955 Acc: 0.6290\n","\n","Epoch 1/29\n","----------\n","train Loss: 1.1172 Acc: 0.6228\n","val Loss: 0.9475 Acc: 0.6990\n","\n","Epoch 2/29\n","----------\n","train Loss: 1.0160 Acc: 0.6670\n","val Loss: 0.8721 Acc: 0.7230\n","\n","Epoch 3/29\n","----------\n","train Loss: 0.9456 Acc: 0.6848\n","val Loss: 0.8437 Acc: 0.7130\n","\n","Epoch 4/29\n","----------\n"]}]},{"cell_type":"code","metadata":{"id":"PUuTtVg6X91r"},"source":["model = torchvision.models.resnet50(pretrained=True)\n","result=[]\n","for class_num in range(len(classes)):\n","  predictions=test(model,class_num)\n","  result.append(predictions.cpu().numpy())\n","result=np.matrix(result)\n","result=result.T\n","np.savetxt('prediction.txt', np.c_[result],\n"," fmt='%d',delimiter='\\t')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Xk26HUA9VkX","executionInfo":{"elapsed":1716,"status":"ok","timestamp":1634228428471,"user":{"displayName":"苏志翔","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06444298763113069178"},"user_tz":-480},"outputId":"f79d900b-061e-4d77-8a19-c658a5f10074"},"source":["!tar -cvf state.tar *.pth"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["final_state_for_class_0.pth\n","final_state_for_class_1.pth\n","final_state_for_class_2.pth\n","final_state_for_class_3.pth\n","final_state_for_class_4.pth\n","final_state_for_class_5.pth\n"]}]}]}